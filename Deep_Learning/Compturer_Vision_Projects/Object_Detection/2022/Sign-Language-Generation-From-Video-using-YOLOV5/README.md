# Machine_Learning

#### Conversing with people having a hearing disability is a major challenge. Deaf and Mute people use hand gesture sign language to communicate, hence normal people face problems in recognizing their language by signs made. Hence there is a need for systems that recognize the different signs and conveys the information to normal people.

![Alt Text](https://wp.dailybruin.com/images/2020/08/787CA2F1-ED0B-4C2E-83FD-FFF4140712F0.png)

#### In this sign language detection project we trained with 5 signs namely 'Hello','Yes','No','Thanks','IloveYou'

![Alt Text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSBgfAfVyslUzkv4TUXQP5RZnMhX6Y0lJbEqA&usqp=CAU)

#### You can find the dataset used for this project in the location Data\Sign_language_data.zip having the both train and test data with annotations. For the annotation of custom images you can use the Annotation Tool present in the git repo. 

#### The sample test images we capture at the end of our project you can find them below
![Alt Text](img1)
![Alt Text](img2)

![Alt Text](https://cdna.artstation.com/p/assets/images/images/042/676/328/original/leo-bryan-arief-sprite-0002.gif?1635169542)
